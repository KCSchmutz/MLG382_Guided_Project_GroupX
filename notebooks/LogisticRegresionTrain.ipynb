{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46926919",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47949fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:38: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:38: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Karl\\AppData\\Local\\Temp\\ipykernel_13980\\1169166835.py:38: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df = load_data('..\\data\\Student_performance_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2392 entries, 0 to 2391\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Age                2392 non-null   int64  \n",
      " 1   Gender             2392 non-null   object \n",
      " 2   Ethnicity          2392 non-null   object \n",
      " 3   ParentalEducation  2392 non-null   object \n",
      " 4   StudyTimeWeekly    2392 non-null   float64\n",
      " 5   Absences           2392 non-null   int64  \n",
      " 6   Tutoring           2392 non-null   int64  \n",
      " 7   ParentalSupport    2392 non-null   object \n",
      " 8   Extracurricular    2392 non-null   int64  \n",
      " 9   Sports             2392 non-null   int64  \n",
      " 10  Music              2392 non-null   int64  \n",
      " 11  Volunteering       2392 non-null   int64  \n",
      " 12  GPA                2392 non-null   float64\n",
      " 13  GradeClass         2392 non-null   object \n",
      "dtypes: float64(2), int64(7), object(5)\n",
      "memory usage: 261.8+ KB\n",
      "               Age  StudyTimeWeekly     Absences     Tutoring  \\\n",
      "count  2392.000000      2392.000000  2392.000000  2392.000000   \n",
      "mean     16.468645         9.771992    14.541388     0.301421   \n",
      "std       1.123798         5.652774     8.467417     0.458971   \n",
      "min      15.000000         0.001057     0.000000     0.000000   \n",
      "25%      15.000000         5.043079     7.000000     0.000000   \n",
      "50%      16.000000         9.705363    15.000000     0.000000   \n",
      "75%      17.000000        14.408410    22.000000     1.000000   \n",
      "max      18.000000        19.978094    29.000000     1.000000   \n",
      "\n",
      "       Extracurricular       Sports        Music  Volunteering          GPA  \n",
      "count      2392.000000  2392.000000  2392.000000   2392.000000  2392.000000  \n",
      "mean          0.383361     0.303512     0.196906      0.157191     1.906186  \n",
      "std           0.486307     0.459870     0.397744      0.364057     0.915156  \n",
      "min           0.000000     0.000000     0.000000      0.000000     0.000000  \n",
      "25%           0.000000     0.000000     0.000000      0.000000     1.174803  \n",
      "50%           0.000000     0.000000     0.000000      0.000000     1.893393  \n",
      "75%           1.000000     1.000000     0.000000      0.000000     2.622216  \n",
      "max           1.000000     1.000000     1.000000      1.000000     4.000000  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Male'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_13980\\1169166835.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     67\u001b[39m X_train, X_test, Y_train, Y_test = create_train_test_split(X, y)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# reloading and training the deeplearning model\u001b[39;00m\n\u001b[32m     69\u001b[39m model=get_model(\u001b[33m'logistic_regresion'\u001b[39m)\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# model training and evaliation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m train_model(model, \u001b[33m'logistic_regresion'\u001b[39m, X_train, X_test, Y_train, Y_test)\n",
      "\u001b[32mc:\\Users\\Karl\\source\\repos\\ApexCareSolutions\\MLG382_Guided_Project_GroupX\\src\\train_models.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(model, model_name, X_train, X_test, Y_train, Y_test, output_dir)\u001b[39m\n\u001b[32m    130\u001b[39m         \u001b[38;5;66;03m#Only encoding the pyplines catagorical features\u001b[39;00m\n\u001b[32m    131\u001b[39m         pipeline = make_pipeline(model)\n\u001b[32m    132\u001b[39m \n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m#Trains entire pipeline\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     pipeline.fit(X_train, Y_train)\n\u001b[32m    135\u001b[39m \n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m#Predicts test set results\u001b[39;00m\n\u001b[32m    137\u001b[39m     Y_pred = pipeline.predict(X_test)\n",
      "\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1385\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m                 )\n\u001b[32m   1388\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    658\u001b[39m                     step_idx=len(self) - \u001b[32m1\u001b[39m,\n\u001b[32m    659\u001b[39m                     step_params=routed_params[self.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    660\u001b[39m                     all_params=params,\n\u001b[32m    661\u001b[39m                 )\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m                 self._final_estimator.fit(Xt, y, **last_step_params[\u001b[33m\"fit\"\u001b[39m])\n\u001b[32m    663\u001b[39m \n\u001b[32m    664\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self\n",
      "\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1385\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m                 )\n\u001b[32m   1388\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1218\u001b[39m             _dtype = np.float64\n\u001b[32m   1219\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1220\u001b[39m             _dtype = [np.float64, np.float32]\n\u001b[32m   1221\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m         X, y = validate_data(\n\u001b[32m   1223\u001b[39m             self,\n\u001b[32m   1224\u001b[39m             X,\n\u001b[32m   1225\u001b[39m             y,\n",
      "\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2957\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2958\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2959\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2960\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2961\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2962\u001b[39m         out = X, y\n\u001b[32m   2963\u001b[39m \n\u001b[32m   2964\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1366\u001b[39m         )\n\u001b[32m   1367\u001b[39m \n\u001b[32m   1368\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1369\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m     X = check_array(\n\u001b[32m   1371\u001b[39m         X,\n\u001b[32m   1372\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1373\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1052\u001b[39m                         )\n\u001b[32m   1053\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1055\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m                 raise ValueError(\n\u001b[32m   1058\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    835\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    836\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    837\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    840\u001b[39m \n\u001b[32m    841\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2149\u001b[39m     def __array__(\n\u001b[32m   2150\u001b[39m         self, dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2151\u001b[39m     ) -> np.ndarray:\n\u001b[32m   2152\u001b[39m         values = self._values\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m         arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2154\u001b[39m         if (\n\u001b[32m   2155\u001b[39m             astype_is_view(values.dtype, arr.dtype)\n\u001b[32m   2156\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Male'"
     ]
    }
   ],
   "source": [
    "#Importing Required Libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Import the python libraies from source\n",
    "#Allows for model to reload without reloading Kernel\n",
    "import importlib \n",
    "\n",
    "#Python files can be used \n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "#prepare_data.py file importing functions\n",
    "from prepare_data import (\n",
    "    load_data,\n",
    "    catagorical_column_transformations,\n",
    "    feature_engineering\n",
    "    \n",
    ")\n",
    "#preprocess_data.py file importing functions\n",
    "from preprocess_data import (\n",
    "    scale_and_encode,\n",
    "    remove_anomalies,\n",
    "    get_numeric_columns,\n",
    "    iterative_outlier_removal,\n",
    "    make_Onehot\n",
    ")\n",
    "#train_models.py file importing functions\n",
    "from train_models import (\n",
    "    split_features_target,\n",
    "    create_train_test_split,\n",
    "    get_model,\n",
    "    train_model\n",
    ")\n",
    "\n",
    "\n",
    "# Data preparation\n",
    "# load the data using the load_data function from prepare_data.py\n",
    "df = load_data('..\\data\\Student_performance_data.csv')\n",
    "print(df.describe(df.info()))\n",
    "\n",
    "# decode the catagorical features\n",
    "df = catagorical_column_transformations(df)\n",
    "# perform feature engineering using the feature_engineering function from prepare_data.py\n",
    "df = feature_engineering(df)\n",
    "# Preprocessing\n",
    "# scale and encode the data using the scale_and_encode function from preprocess_data.py\n",
    "df = scale_and_encode(df)\n",
    "\n",
    "#print(df.columns.to_list())\n",
    "# remove anomalies using the remove_anomalies function from preprocess_data.py\n",
    "#   df = remove_anomalies(df) ~ Removing the anaomalies might break the model\n",
    "\n",
    "# get the numeric columns using the get_numeric_columns function from preprocess_data.py\n",
    "numeric_columns = get_numeric_columns(df)\n",
    "# iterative outlier removal using the iterative_outlier_removal function from preprocess_data.py\n",
    "df = iterative_outlier_removal(df, numeric_columns)\n",
    "# make the data one-hot\n",
    "df = make_Onehot(df)\n",
    "# Model preparation\n",
    "X, y = split_features_target(df)\n",
    "\n",
    "# Ensure the target variable `y` contains discrete classes\n",
    "# Convert continuous values in `y` into binary classes (e.g., 0 and 1) based on a threshold\n",
    "threshold = 0.0  # You can adjust this threshold as needed\n",
    "y = (y > threshold).astype(int)\n",
    "# create an train test plit\n",
    "X_train, X_test, Y_train, Y_test = create_train_test_split(X, y)\n",
    "# reloading and training the deeplearning model\n",
    "model=get_model('logistic_regresion')\n",
    "# model training and evaliation\n",
    "train_model(model, 'logistic_regresion', X_train, X_test, Y_train, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
