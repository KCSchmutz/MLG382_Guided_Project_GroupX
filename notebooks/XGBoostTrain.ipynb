{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:38: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:38: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Karl\\AppData\\Local\\Temp\\ipykernel_44692\\2333588591.py:38: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df = load_data('..\\data\\Student_performance_data.csv')\n",
      "c:\\Users\\Karl\\source\\repos\\ApexCareSolutions\\MLG382_Guided_Project_GroupX\\src\\preprocess_data.py:68: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace({False: 0.0, True: 1.0})\n",
      "C:\\Users\\Karl\\AppData\\Local\\Temp\\ipykernel_44692\\2333588591.py:38: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df = load_data('..\\data\\Student_performance_data.csv')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     61\u001b[39m model=get_model(\u001b[33m'\u001b[39m\u001b[33mxgboost\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# model training and evaliation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m train_model(model, \u001b[33m'\u001b[39m\u001b[33mxgboost\u001b[39m\u001b[33m'\u001b[39m, X_train, X_test, Y_train, Y_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Karl\\source\\repos\\ApexCareSolutions\\MLG382_Guided_Project_GroupX\\src\\train_models.py:148\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, model_name, X_train, X_test, Y_train, Y_test, output_dir)\u001b[39m\n\u001b[32m    145\u001b[39m pipeline.fit(X_train, Y_train)\n\u001b[32m    147\u001b[39m \u001b[38;5;66;03m#Predicts test set results\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m Y_pred = pipeline.predict(X_test)\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m#Prints evaluatoin metrics for each model\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\pipeline.py:782\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    740\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Transform the data, and apply `predict` with the final estimator.\u001b[39;00m\n\u001b[32m    741\u001b[39m \n\u001b[32m    742\u001b[39m \u001b[33;03mCall `transform` of each transformer in the pipeline. The transformed\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    779\u001b[39m \u001b[33;03m    Result of calling `predict` on the final estimator.\u001b[39;00m\n\u001b[32m    780\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    781\u001b[39m \u001b[38;5;66;03m# TODO(1.8): Remove the context manager and use check_is_fitted(self)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _raise_or_warn_if_not_fitted(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    783\u001b[39m     Xt = X\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\contextlib.py:144\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    146\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\pipeline.py:60\u001b[39m, in \u001b[36m_raise_or_warn_if_not_fitted\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# we only get here if the above didn't raise\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     check_is_fitted(estimator)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError:\n\u001b[32m     62\u001b[39m     warnings.warn(\n\u001b[32m     63\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis Pipeline instance is not fitted yet. Call \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m'\u001b[39m\u001b[33m with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     64\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mappropriate arguments before using other methods such as transform, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m     68\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\utils\\validation.py:1756\u001b[39m, in \u001b[36mcheck_is_fitted\u001b[39m\u001b[34m(estimator, attributes, msg, all_or_any)\u001b[39m\n\u001b[32m   1753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags.requires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1754\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[32m   1757\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg % {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator).\u001b[34m__name__\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\utils\\validation.py:1665\u001b[39m, in \u001b[36m_is_fitted\u001b[39m\u001b[34m(estimator, attributes, all_or_any)\u001b[39m\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m all_or_any([\u001b[38;5;28mhasattr\u001b[39m(estimator, attr) \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m attributes])\n\u001b[32m   1664\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[33m\"\u001b[39m\u001b[33m__sklearn_is_fitted__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator.__sklearn_is_fitted__()\n\u001b[32m   1667\u001b[39m fitted_attrs = [\n\u001b[32m   1668\u001b[39m     v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v.endswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v.startswith(\u001b[33m\"\u001b[39m\u001b[33m__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1669\u001b[39m ]\n\u001b[32m   1670\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fitted_attrs) > \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\pipeline.py:1321\u001b[39m, in \u001b[36mPipeline.__sklearn_is_fitted__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1317\u001b[39m     \u001b[38;5;66;03m# check if the last step of the pipeline is fitted\u001b[39;00m\n\u001b[32m   1318\u001b[39m     \u001b[38;5;66;03m# we only check the last step since if the last step is fit, it\u001b[39;00m\n\u001b[32m   1319\u001b[39m     \u001b[38;5;66;03m# means the previous steps should also be fit. This is faster than\u001b[39;00m\n\u001b[32m   1320\u001b[39m     \u001b[38;5;66;03m# checking if every step of the pipeline is fit.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1321\u001b[39m     check_is_fitted(last_step)\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1323\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\utils\\validation.py:1751\u001b[39m, in \u001b[36mcheck_is_fitted\u001b[39m\u001b[34m(estimator, attributes, msg, all_or_any)\u001b[39m\n\u001b[32m   1748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is not an estimator instance.\u001b[39m\u001b[33m\"\u001b[39m % (estimator))\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m tags = get_tags(estimator)\n\u001b[32m   1753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags.requires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1754\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\utils\\_tags.py:430\u001b[39m, in \u001b[36mget_tags\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator).mro()):\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m         sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    431\u001b[39m         class_order.append(klass)\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_more_tags\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Karl\\anaconda3\\envs\\MLG382_class\\Lib\\site-packages\\sklearn\\base.py:613\u001b[39m, in \u001b[36mRegressorMixin.__sklearn_tags__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     tags = \u001b[38;5;28msuper\u001b[39m().__sklearn_tags__()\n\u001b[32m    614\u001b[39m     tags.estimator_type = \u001b[33m\"\u001b[39m\u001b[33mregressor\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m     tags.regressor_tags = RegressorTags()\n",
      "\u001b[31mAttributeError\u001b[39m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "#Importing Required Libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Import the python libraies from source\n",
    "#Allows for model to reload without reloading Kernel\n",
    "import importlib \n",
    "\n",
    "#Python files can be used \n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "#prepare_data.py file importing functions\n",
    "from prepare_data import (\n",
    "    load_data,\n",
    "    catagorical_column_transformations,\n",
    "    feature_engineering\n",
    "    \n",
    ")\n",
    "#preprocess_data.py file importing functions\n",
    "from preprocess_data import (\n",
    "    scale_and_encode,\n",
    "    remove_anomalies,\n",
    "    get_numeric_columns,\n",
    "    iterative_outlier_removal,\n",
    "    make_Onehot\n",
    ")\n",
    "#train_models.py file importing functions\n",
    "from train_models import (\n",
    "    split_features_target,\n",
    "    create_train_test_split,\n",
    "    get_model,\n",
    "    train_model\n",
    ")\n",
    "\n",
    "\n",
    "# Data preparation\n",
    "# load the data using the load_data function from prepare_data.py\n",
    "df = load_data('..\\data\\Student_performance_data.csv')\n",
    "# decode the catagorical features\n",
    "df = catagorical_column_transformations(df)\n",
    "# perform feature engineering using the feature_engineering function from prepare_data.py\n",
    "df = feature_engineering(df)\n",
    "# Preprocessing\n",
    "# scale and encode the data using the scale_and_encode function from preprocess_data.py\n",
    "df = scale_and_encode(df)\n",
    "#print(df.columns.to_list())\n",
    "# remove anomalies using the remove_anomalies function from preprocess_data.py\n",
    "#   df = remove_anomalies(df) ~ Removing the anaomalies might break the model\n",
    "\n",
    "# get the numeric columns using the get_numeric_columns function from preprocess_data.py\n",
    "numeric_columns = get_numeric_columns(df)\n",
    "# iterative outlier removal using the iterative_outlier_removal function from preprocess_data.py\n",
    "df = iterative_outlier_removal(df, numeric_columns)\n",
    "# make the data one-hot\n",
    "df = make_Onehot(df)\n",
    "# Model preparation\n",
    "X, y = split_features_target(df)\n",
    "# create an train test plit\n",
    "X_train, X_test, Y_train, Y_test = create_train_test_split(X, y)\n",
    "# reloading and training the deeplearning model\n",
    "model=get_model('xgboost')\n",
    "# model training and evaliation\n",
    "train_model(model, 'xgboost', X_train, X_test, Y_train, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLG382_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
